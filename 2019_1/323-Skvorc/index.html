<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (3)--><title>Predicting Slovene Text Complexity Using Readability Measures</title><meta http-equiv="x-ua-compatible" content="ie=edge" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="description" content="" /><meta name="keywords" content="" /><meta name="author" content="Tadej Škvorc University of Ljubljana, Faculty of Computer and Information Science Večna Pot 113 SI-1000 Ljubljana tadej.skvorc@fri.uni-lj.si Jožef Stefan Institute Jamova cesta 39 SI-1000 Ljubljana, Simon Krek Jožef Stefan Institute Jamova cesta 39 SI-1000 Ljubljana University of Ljubljana, Faculty of Arts Aškerčeva 2 SI-1000 Ljubljana simon.krek@guest.arnes.si, Senja Pollak Jožef Stefan Institute Jamova cesta 39 SI-1000 Ljubljana senja.pollak@ijs.si, Špela Arhar Holdt University of Ljubljana, Faculty of Arts Aškerčeva 2 SI-1000 Ljubljana spela.arharholdt@ff.uni-lj.si University of Ljubljana, Faculty of Computer and Information Science Večna Pot 113 SI-1000 Ljubljana, and Marko Robnik-Šikonja University of Ljubljana, Faculty of Computer and Information Science Večna Pot 113 SI-1000 Ljubljana marko.robnik@fri.uni-lj.si" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta charset="utf-8" /><link href="http://www2.sistory.si/publikacije/themes/foundation/6/css/foundation.min.css" rel="stylesheet" type="text/css" /><link href="http://www2.sistory.si/publikacije/themes/css/foundation/6/sistory.css" rel="stylesheet" type="text/css" /><link href="http://cdnjs.cloudflare.com/ajax/libs/foundicons/3.0.0/foundation-icons.min.css" rel="stylesheet" type="text/css" /><link href="http://www2.sistory.si/publikacije/themes/plugin/TipueSearch/6.1/tipuesearch/css/normalize.css" rel="stylesheet" type="text/css" /><link href="http://www2.sistory.si/publikacije/themes/css/plugin/TipueSearch/6.1/my-tipuesearch.css" rel="stylesheet" type="text/css" /><style type="text/css">
         div.stdheader{
           text-align:center;
         }
         
         div.docAuthor{
           text-align:center;
           font-size: 120%;
           }
         
         div.docImprint{
           border-top:3pt solid black;
           border-bottom:1pt solid black;
         }
         
         section.abstract{
           border-bottom:1pt solid black;
         }
         
         section.abstract h2{
           font-size: 120%;
         }
         
         section.summary{
           border-top:1pt solid black;
         }
         
         p.docAuthor{
           text-align:center;
           font-size: 120%;
           }
         
         p {
           text-align: justify;
         }
         
         dl, ol, ul {
           padding: 0 1.25em 0 0.5625em;
           margin-bottom: 1rem;
         }
      </style><script src="http://www2.sistory.si/publikacije/themes/foundation/6/js/vendor/jquery.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=Accessible-full"></script></head><body class="simple" id="TOP" itemscope="itemscope" itemtype="http://www.tei-c.org/ns/1.0/" itemprop="TEI"><div class="column row"><div class="stdheader autogenerated"><h2 lang="en" class="maintitle" itemprop="TEI"><i>Predicting Slovene Text Complexity Using Readability Measures</i></h2></div><!--TEI  front matter --><div class="tei_front"><div class="docAuthor">Tadej Škvorc<span id="ftn1_return"><a class="notelink" title="University of Ljubljana, Faculty of Computer and Information Science, Večna Pot 113, SI-1000 Ljubljana, Jožef Stefan Institute, Jamova cesta 39, SI-10…" href="#ftn1"><sup>*</sup></a></span></div><div class="docAuthor">Simon Krek<span id="ftn2_return"><a class="notelink" title="Jožef Stefan Institute, Jamova cesta 39, SI-1000 Ljubljana, University of Ljubljana, Faculty of Arts, Aškerčeva 2, SI-1000 Ljubljana, simon.krek@guest…" href="#ftn2"><sup>**</sup></a></span></div><div class="docAuthor">Senja Pollak<span id="ftn3_return"><a class="notelink" title="Jožef Stefan Institute, Jamova cesta 39, SI-1000 Ljubljana, senja.pollak@ijs.si" href="#ftn3"><sup>∗∗∗</sup></a></span></div><div class="docAuthor">Špela Arhar Holdt<span id="ftn4_return"><a class="notelink" title="University of Ljubljana, Faculty of Arts, Aškerčeva 2, SI-1000 Ljubljana, University of Ljubljana, Faculty of Computer and Information Science, Večna …" href="#ftn4"><sup>∗∗∗∗</sup></a></span></div><div class="docAuthor">Marko Robnik-Šikonja<span id="ftn5_return"><a class="notelink" title="University of Ljubljana, Faculty of Computer and Information Science, Večna Pot 113, SI-1000 Ljubljana, marko.robnik@fri.uni-lj.si" href="#ftn5"><sup>∗∗∗∗∗</sup></a></span></div><div class="docImprint"> Cobiss type: 1.01 <br />UDC: 003.295:821.163.6</div><section lang="sl" class="abstract" id="index-front.1_div.1"><header><h2 lang="sl"><span class="head" itemprop="head">IZVLEČEK</span><br style="text-transform: uppercase;" itemprop="head" /><span style="text-transform: uppercase;" itemprop="head">Napovedovanje kompleksnosti slovenskih besedil z uporabo mer berljivosti</span></h2></header><p id="index-p-d46e250"><span class="numberParagraph">1</span><span style="font-style:italic" itemprop="hi">Večina obstoječih formul za merjenje berljivosti je zasnovana za besedila v angleškem jeziku, na katerih je tudi ocenjena njihova kakovost. V našem članku predstavimo prilagoditev izbranih mer za slovenščino. Uspešnost desetih znanih formul ter osmih dodatnih kriterijev berljivosti ocenimo na petih skupinah besedil: otroških revijah, splošnih revijah, časopisih, tehničnih revijah in zapisnikih sej državnega zbora. Te skupine besedil imajo različne ciljne publike, zaradi česar predpostavimo, da uporabljajo različne stile pisanja, ki bi jih formule in kriteriji berljivosti morali zaznati. V analizi pokažemo, katere formule in kriteriji berljivosti delujejo dobro in s katerimi razlik med skupinami nismo mogli zaznati.</span></p><p id="index-p-d46e254"><span class="numberParagraph">2</span><span style="font-style:italic" itemprop="hi">Ključne besede: berljivost, obdelava naravnega jezika, analiza besedil</span></p></section><section lang="en" class="abstract" id="index-front.1_div.2"><header><h2 lang="en"><span class="head" itemprop="head">ABSTRACT</span></h2></header><p id="index-p-d46e260"><span class="numberParagraph">1</span><span style="font-style:italic" itemprop="hi">The majority of existing readability measures are designed for English texts. We aim to adapt and test the readability measures on Slovene. We test ten well-known readability formulas and eight additional readability criteria on five types of texts: children’s magazines, general magazines, daily newspapers, technical magazines, and transcriptions of national assembly sessions. As these groups of texts target different audiences, we assume that the differences in writing styles should be reflected in their readability scores. Our analysis shows which readability measures perform well on this task and which fail to distinguish between the groups.</span></p><p id="index-p-d46e265"><span class="numberParagraph">2</span><span style="font-style:italic" itemprop="hi">Keywords: readability, natural language processing, text analysis</span></p></section></div><!--TEI body matter --><div class="tei_body"><section class="teidiv0" id="index-body.1_div.1"><header><h2><span class="headingNumber">1. </span><span class="head" itemprop="head">Introduction</span></h2></header><p id="index-p-d46e272"><span class="numberParagraph">1</span>In English, the problem of determining text readability (i.e. how easy a text is to understand) has long been a topic of research, with its origins in the 19th century (<a class="link_ref" itemprop="ref" href="#Sherman.1893" title="Sherman Lucius Adelno. 1893. Analytics of literature A manual for the objective study of English prose and poetry. Boston Ginn.">Sherman 1893</a>). Since then, many different methods and readability measures have been developed, often with the goal of determining whether a text is too difficult for its target age group. Even though the question of readability is complex from a linguistic standpoint, a large majority of existing measures are based on simple heuristics. There has been little research on readability of languages other than English, therefore we aim to apply these measures to Slovene and evaluate how well they perform.</p><p id="index-p-d46e277"><span class="numberParagraph">2</span>There are several factors that might cause these measures to perform poorly on non-English languages, such as:</p><ul itemprop="list"><li class="item" itemprop="item" id="d46e279">Many measures are fine-tuned to correspond to the grade levels of the United States education system. It is likely a different fine-tuning would be needed for other languages, as a.) their education system is different from the US system, and b.) the differences in readability between grade levels are likely to be different between languages, meaning that each language would require specifically tuned parameters.</li><li class="item" itemprop="item" id="d46e280">Some measures utilize a list of common English words and their results depend on the definition of this list. For Slovene, there currently does not exist a publicly available list of common words, so it is not known how such measures would perform.</li><li class="item" itemprop="item" id="d46e281">The existing readability measures do not use the morphological information to determine difficult words but rely on syllable and character counts, or a list of difficult words. As Slovene is morphologically much more complex than English, words with complex morphology are harder to understand than those with simple morphology, even if they have the same number of characters or syllables.</li></ul><p id="index-p-d46e282"><span class="numberParagraph">3</span>We analyze the commonly used readability measures (as well as some novel measures) on Slovene texts and propose a word list needed to implement the word-list-based measures. We calculate statistical distributions of scores for each readability measure across subcorpora and assess the ability of measures to distinguish between different subcorpora using a variety of statistical tests. We show that machine learning classification models, using a combination of readability measures, can predict the subcorpus a given text belongs to. </p><p id="index-p-d46e283"><span class="numberParagraph">4</span>The paper extends the short version of the paper presented in <a class="link_ref" itemprop="ref" href="#%C5%A0kvorc.2018" title="Škvorc Tadej Simon Krek Senja Pollak Špela Arhar Holdt and Marko RobnikŠikonja. 2018. Evaluation of Statistical Readability Mea...">Škvorc et al. (2018)</a> and is structured as follows. We first present the related work on readability measures and describe the readability measures used in our analysis. The methodology of the analysis is presented next, followed by the results split into three sections. The last section concludes the paper and presents ideas for further work.</p></section><section class="teidiv0" id="index-body.1_div.2"><header><h2><span class="headingNumber">2. </span><span class="head" itemprop="head">Related Work</span></h2></header><p id="index-p-d46e290"><span class="numberParagraph">1</span>For English, there exists a variety of works focused on determining readability by using readability formulas. Those formulas rely on different features of the text such as the average sentence length, percentage of difficult words, and the average number of characters per word. Examples of such measures include the Coleman-Liau index (<a class="link_ref" itemprop="ref" href="#Coleman.1975" title="Coleman Meri and Ta Lin Liau. 1975. A computer readability formula designed for machine scoring. Journal of Applied Psychology ...">Coleman and Liau 1975</a>), LIX (<a class="link_ref" itemprop="ref" href="#Bj%C3%B6rnsson.1968" title="Björnsson Carl Hugo. 1968. Läsbarhet. Liber.">Björnsson 1968</a>), and the automated readability index (ARI) (<a class="link_ref" itemprop="ref" href="#Senter.1967" title="Senter R. J. and Edgar A. Smith. 1967. Automated readability index. Ohio University of Cincinnati.">Senter and Smith 1967</a>). Some formulas, like the Flesch-Kincaid grade level (<a class="link_ref" itemprop="ref" href="#Kincaid.1975" title="Kincaid J. Peter Robert P. Fishburne Jr Richard L. Rogers and Brad S. Chissom. 1975. Derivation of new readability formulas (Au...">Kincaid et al. 1975</a>) and SMOG (<a class="link_ref" itemprop="ref" href="#McLaughlin.1969" title="Mc Laughlin G. Harry. 1969. SMOG grading  a new readability formula. Journal of reading 12 No. 8 63946.">Mc Laughlin 1969</a>) use the number of syllables per word to determine if a word is difficult. Additionally, some measures (e.g., the Spache readability formula (<a class="link_ref" itemprop="ref" href="#Spache.1953" title="Spache George. 1953. A new readability formula for primarygrade reading materials. The Elementary School Journal 53 No. 7 41013...">Spache 1953</a>) and Dale-Chall readability formula (<a class="link_ref" itemprop="ref" href="#Dale.1948" title="Dale Edgar and Jeanne S. Chall. 1948. A formula for predicting readability Instructions. Educational research bulletin 3754.">Dale and Chall 1948</a>) rely on a pre-constructed list of difficult words.</p><p id="index-p-d46e314"><span class="numberParagraph">2</span>Aside from the readability formulas, there exists a variety of other approaches that can be used to determine readability (<a class="link_ref" itemprop="ref" href="#Bailin.2016" title="Bailin Alan and Ann Grafstein. 2016. Readability Text and context. Springer.">Bailin and Grafstein 2016</a>). For example, various machine-learning approaches can be used to obtain better results than readability formulas, such as the approach presented in <a class="link_ref" itemprop="ref" href="#Fran%C3%A7ois.2012" title="François Thomas and Eleni Miltsakaki. 2012. Do NLP and machine learning improve traditional readability formulas In Proceedings...">Francois and Miltsakaki (2012)</a>, which outperforms readability formulas on French text.</p><p id="index-p-d46e322"><span class="numberParagraph">3</span>There is little work attempting to apply these measures to Slovene texts. Most work dealing with the readability of Slovene text is focused on manual methods. For example, <a class="link_ref" itemprop="ref" href="#Justin.2003" title="Justin J. 2003. Učbenik kot dejavnik uspešnosti kurikularne prenove poročilo o rezultatih evalvacijske študije.">Justin (2009)</a> analyzes Slovene textbooks from a variety of angles, including readability. On the other hand, works that focus on automatic readability measures are rare. <a class="link_ref" itemprop="ref" href="#ZwitterVitez.2014" title="Zwitter Vitez Ana. 2014. Ugotavljanje avtorstva besedil primer Trenirkarjev. In zbornik Devete konference Jezikovne Tehnologije...">Zwitter Vitez (2014)</a> uses a variety of readability measures for author recognition in Slovene text, but we found no works that used them to determine readability.</p><p id="index-p-d46e330"><span class="numberParagraph">4</span>In addition to Slovene, some related works evaluate readability measures on other languages. <a class="link_ref" itemprop="ref" href="#D%C4%99bowski.2015" title="Dębowski Łukasz Bartosz Broda Bartłomiej Nitoń and Edyta Charzyńska. 2015. JasnopisA Program to Compute Readability of Texts in...">Debowski et al. (2015)</a> evaluate readability formulas on Polish text and show that they obtain better results by using a more complex, machine-learning-based approach.</p></section><section class="teidiv0" id="index-body.1_div.3"><header><h2><span class="headingNumber">3. </span><span class="head" itemprop="head">Readability Measures</span></h2></header><p id="index-p-d46e337"><span class="numberParagraph">1</span>In our analysis, we used two groups of readability measures:</p><ul itemprop="list"><li class="item" itemprop="item" id="d46e339"><span style="font-weight:bold" itemprop="hi">Existing readability formulas for English:</span> we focused mainly on popular methods that have been shown to achieve good results on English texts. These measures mostly rely on easy-to-obtain features such as a number of difficult words, sentence length, and word length.</li><li class="item" itemprop="item" id="d46e343"><span style="font-weight:bold" itemprop="hi">Natural-language-processing-based readability criteria:</span> we used additional criteria that are not present in the existing readability formulas but can be obtained from tools for automatic language processing, such as the percentage of verbs, number of unique words, and morphological difficulty of words. In the existing English formulas, such criteria are not used but they might contain useful information for determining the readability of Slovene texts.</li></ul><p id="index-p-d46e347"><span class="numberParagraph">2</span>In the following two subsections we present the established readability measures for grading English text and our proposed additional criteria.</p></section><section class="teidiv0" id="index-body.1_div.4"><header><h2><span class="headingNumber">4. </span><span class="head" itemprop="head">Existing Readability Formulas</span></h2></header><p id="index-p-d46e350"><span class="numberParagraph">1</span>There exists a variety of ways to measure the readability of texts written in English. For our analysis, we used 10 readability formulas given below. The entities used in the expressions correspond to the number of occurrences of a given entity, e.g., word corresponds to the number of words in a measured text.</p><ul itemprop="list"><li class="item" itemprop="item" id="d46e352"><span style="font-weight:bold" itemprop="hi">Gunning fog index</span> (<a class="link_ref" itemprop="ref" href="#Gunning.1952" title="Gunning Robert. 1952. The technique of clear writing. McGrawHill.">Gunning 1952</a>) is calculated as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">GFI</mi><mo>=</mo><mn>0.4</mn><mfrac><mrow><mi mathvariant="normal">words</mi></mrow><mrow><mi mathvariant="normal">sentences</mi></mrow></mfrac><mo>+</mo><mn>100</mn><mfrac><mrow><mi mathvariant="normal">complex words</mi></mrow><mrow><mi mathvariant="normal">words</mi></mrow></mfrac><mtext>, </mtext></math> where a word is considered complex if it contains three or more syllables. As there exists no established automatic method for counting syllables of Slovene words, we used a rule-based approach designed for English. The resulting score is calibrated to the grade level of the USA education system.</li><li class="item" itemprop="item" id="d46e389"><span style="font-weight:bold" itemprop="hi">Flesch reading ease</span> (<a class="link_ref" itemprop="ref" href="#Kincaid.1975" title="Kincaid J. Peter Robert P. Fishburne Jr Richard L. Rogers and Brad S. Chissom. 1975. Derivation of new readability formulas (Au...">Kincaid et al. 1975</a>) is calculated as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">FRE</mi><mo>=</mo><mn>206.835</mn><mo>-</mo><mn>1.015</mn><mfrac><mrow><mi mathvariant="normal">words</mi></mrow><mrow><mi mathvariant="normal">sentences</mi></mrow></mfrac><mo>-</mo><mn>84.6</mn><mfrac><mrow><mi mathvariant="normal">syllables</mi></mrow><mrow><mi mathvariant="normal">words</mi></mrow></mfrac><mtext>.</mtext></math> The score does not correspond to grade levels. Instead, the higher the value, the easier the text is considered to be. A text with a score of 100 should be easily understood by 11-year-old students, while a text with a score of 0 should be intended for university graduates.</li><li class="item" itemprop="item" id="d46e430"><span style="font-weight:bold" itemprop="hi">Flesch–Kincaid grade level</span> (<a class="link_ref" itemprop="ref" href="#Kincaid.1975" title="Kincaid J. Peter Robert P. Fishburne Jr Richard L. Rogers and Brad S. Chissom. 1975. Derivation of new readability formulas (Au...">Kincaid et al. 1975</a>) is similar to Flesch reading ease, but does correspond to grade levels. It is calculated as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">FKGL</mi><mo>=</mo><mn>0.39</mn><mfrac><mrow><mi mathvariant="normal">words</mi></mrow><mrow><mi mathvariant="normal">sentences</mi></mrow></mfrac><mo>+</mo><mn>11.8</mn><mfrac><mrow><mi mathvariant="normal">syllables</mi></mrow><mrow><mi mathvariant="normal">words</mi></mrow></mfrac><mo>-</mo><mn>15.59</mn><mtext>.</mtext></math></li><li class="item" itemprop="item" id="d46e470"><span style="font-weight:bold" itemprop="hi">Dale–Chall readability formula</span> (<a class="link_ref" itemprop="ref" href="#Dale.1948" title="Dale Edgar and Jeanne S. Chall. 1948. A formula for predicting readability Instructions. Educational research bulletin 3754.">Dale and Chall 1948</a>) is calculated as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">DCRF</mi><mo>=</mo><mn>0.1579</mn><mfrac><mrow><mi mathvariant="normal">difficult words</mi></mrow><mrow><mi mathvariant="normal">words</mi></mrow></mfrac><mo>+</mo><mn>0.0496</mn><mfrac><mrow><mi mathvariant="normal">words</mi></mrow><mrow><mi mathvariant="normal">sentences</mi></mrow></mfrac><mtext>.</mtext></math><p id="index-p-d46e506"><span class="numberParagraph">1</span>The formula requires a predefined list of common (easy) words and the words which are not on the list are considered as difficult. The novelty of the Dale-Chall Formula was that it did not use word-length counts but a count of “hard” words which do not appear on a specially designed list of common words. This list was defined as the words familiar to most of the 4th-grade students: when 80 percent of the fourth-graders indicated that they knew a word, the word was added to the list.</p> <p id="index-p-d46e508"><span class="numberParagraph">2</span>Higher scores indicate that the text is harder, but the resulting score does not correspond to grade levels, nor is it appropriate for text aimed at children below 4th grade. In our analysis, we obtained the difficult words in two ways:</p> <ol itemprop="list"><li class="item" itemprop="item" id="d46e511">By constructing a list of “easy” words and considering every word not on the list as difficult. The list of easy words is described later in the paper.</li><li class="item" itemprop="item" id="d46e512">By considering words with more than seven characters as difficult.</li></ol></li><li class="item" itemprop="item" id="d46e513"><span style="font-weight:bold" itemprop="hi">Spache readability formula</span> (<a class="link_ref" itemprop="ref" href="#Spache.1953" title="Spache George. 1953. A new readability formula for primarygrade reading materials. The Elementary School Journal 53 No. 7 41013...">Spache 1953</a>) is calculated as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">SRF</mi><mo>=</mo><mn>0.141</mn><mfrac><mrow><mi mathvariant="normal">words</mi></mrow><mrow><mi mathvariant="normal">sentences</mi></mrow></mfrac><mo>+</mo><mn>8.6</mn><mfrac><mrow><mi mathvariant="normal">unique difficult words</mi></mrow><mrow><mi mathvariant="normal">unique words</mi></mrow></mfrac><mo>+</mo><mn>0.839</mn><mtext>.</mtext></math> Difficult words are defined as words that do not appear in the list of commonly used words, which is the same as the one used in the Dale–Chall readability formula. This method was specifically designed for texts targeting children up to the fourth grade and was not designed to perform well on harder text. The obtained score corresponds to grade levels.</li><li class="item" itemprop="item" id="d46e554"><span style="font-weight:bold" itemprop="hi">Automated readability index</span> (<a class="link_ref" itemprop="ref" href="#Senter.1967" title="Senter R. J. and Edgar A. Smith. 1967. Automated readability index. Ohio University of Cincinnati.">Senter and Smith 1967</a>) is calculated as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">ARI</mi><mo>=</mo><mn>4.71</mn><mfrac><mrow><mi mathvariant="normal">characters</mi></mrow><mrow><mi mathvariant="normal">words</mi></mrow></mfrac><mo>+</mo><mn>0.5</mn><mfrac><mrow><mi mathvariant="normal">words</mi></mrow><mrow><mi mathvariant="normal">sentences</mi></mrow></mfrac><mo>-</mo><mn>21.43</mn><mtext>.</mtext></math> The formula was designed so that it could be automatically captured in times when texts were written on typewriters and therefore it does not use information relating to syllables or difficult words. The obtained score corresponds to grade levels.</li><li class="item" itemprop="item" id="d46e595"><span style="font-weight:bold" itemprop="hi">SMOG (Simple Measure of Gobbledygook)</span> (<a class="link_ref" itemprop="ref" href="#McLaughlin.1969" title="Mc Laughlin G. Harry. 1969. SMOG grading  a new readability formula. Journal of reading 12 No. 8 63946.">McLaughlin 1969</a>) can be calculated as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">SMOG</mi><mo>=</mo><mn>1.043</mn><mroot><mrow><mi mathvariant="normal">difficult words</mi><mfrac><mrow><mn>30</mn></mrow><mrow><mi mathvariant="normal">sentences</mi></mrow></mfrac></mrow><mrow></mrow></mroot><mo>+</mo><mn>3.1291</mn><mtext>,</mtext></math> where difficult words are defined as words with three or more syllables. The score corresponds to grade levels.</li><li class="item" itemprop="item" id="d46e629"><span style="font-weight:bold" itemprop="hi">LIX</span> (<a class="link_ref" itemprop="ref" href="#Bj%C3%B6rnsson.1968" title="Björnsson Carl Hugo. 1968. Läsbarhet. Liber.">Bjornsson 1968</a>) is calculated as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">LIX</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">words</mi></mrow><mrow><mi mathvariant="normal">sentences</mi></mrow></mfrac><mo>+</mo><mn>100</mn><mfrac><mrow><mi mathvariant="normal">long words</mi></mrow><mrow><mi mathvariant="normal">words</mi></mrow></mfrac><mtext>,</mtext></math> where long words are defined as words consisting of more than six characters. LIX is the only measure we used that was not designed specifically for English but for a variety of languages. Because of this, it does not use syllables or a list of unique words. The score does not correspond to grade levels.</li><li class="item" itemprop="item" id="d46e664"><span style="font-weight:bold" itemprop="hi">RIX</span> (<a class="link_ref" itemprop="ref" href="#Anderson.1983" title="Anderson Jonathan. 1983. LIX and RIX Variations on a littleknown readability index. Journal of Reading 26 No. 6 49096.">Anderson 1983</a>) is a simplification of LIX, and is calculated as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">RIX</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">long words</mi></mrow><mrow><mi mathvariant="normal">sentences</mi></mrow></mfrac><mtext>.</mtext></math></li><li class="item" itemprop="item" id="d46e687"><span style="font-weight:bold" itemprop="hi">Coleman-Liau index</span> (<a class="link_ref" itemprop="ref" href="#Coleman.1975" title="Coleman Meri and Ta Lin Liau. 1975. A computer readability formula designed for machine scoring. Journal of Applied Psychology ...">Coleman and Liau 1975</a>) is calculated as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">CLI</mi><mo>=</mo><mn>0.0588</mn><mi mathvariant="normal">L</mi><mo>-</mo><mn>0.296</mn><mi mathvariant="normal">S</mi><mo>-</mo><mn>15.8</mn><mtext>,</mtext></math> where L is the average number of letters per 100 words and S is the average number of sentences per 100 words. The obtained score corresponds to grade levels.</li></ul></section><section class="teidiv0" id="index-body.1_div.5"><header><h2><span class="headingNumber">5. </span><span class="head" itemprop="head">Language-Processing-Based Readability Criteria</span></h2></header><p id="index-p-d46e720"><span class="numberParagraph">1</span>The readability formulas described in the previous section use a low number of common criteria, such as the number of syllables in words or the number of words in a sentence. In our analysis, we also analyzed Slovene texts using the following additional statistics:</p><ul itemprop="list"><li class="item" itemprop="item" id="d46e722">percentage of long words,</li><li class="item" itemprop="item" id="d46e723">percentage of difficult words,</li><li class="item" itemprop="item" id="d46e724">percentage of verbs,</li><li class="item" itemprop="item" id="d46e725">percentage of adjectives,</li><li class="item" itemprop="item" id="d46e726">percentage of unique words,</li><li class="item" itemprop="item" id="d46e727">average sentence length.</li></ul><p id="index-p-d46e728"><span class="numberParagraph">2</span>Many of these (percentage of long words, difficult words, unique words, and average sentence length) are used as features in the readability measures described above. We evaluate them individually to determine how important each of them is for Slovene texts. The <span style="font-weight:bold" itemprop="hi">percentage of verbs</span> is used because a higher number of verbs can indicate more complex sentences with multiple clauses. The <span style="font-weight:bold" itemprop="hi">percentage of adjectives </span>was chosen because we assumed a higher percentage of adjectives could indicate longer, more descriptive sentences that are harder to understand.</p><p id="index-p-d46e736"><span class="numberParagraph">3</span>To take into account richer morphology of Slovene and a less fixed word order compared to English, we computed two additional criteria:</p><ul itemprop="list"><li class="item" itemprop="item" id="d46e738"><span style="font-weight:bold" itemprop="hi">Context of difficult words</span>, which is the average number of difficult words that appear in a context (i.e. the three words before or after the word) of a difficult word. Difficult words are defined as words that do not appear on the list of common words. The intuition behind this metric is that a difficult word that appears in the context of easy words is easier to understand than if it is surrounded by other difficult words since its meaning can be more easily inferred from the context.</li><li class="item" itemprop="item" id="d46e742"><span style="font-weight:bold" itemprop="hi">Average morphological difficulty</span>, where we use the Slovene morphological lexicon Sloleks (<a class="link_ref" itemprop="ref" href="#ArharHoldt.2009" title="Arhar Holdt Špela. 2009. Učni korpus SSJ in leksikon besednih oblik za slovenščino. Jezik in slovstvo 54 No. 34 4356.">Arhar Holdt 2009</a>) to assign a “morphological difficulty” score to each word. Sloleks is a lexicon of word forms and contains frequency information for morphological variants of over 100,000 lemmas (base forms of words as defined in a dictionary). We use the relative frequency of a word variant compared to other variants of the same lemma as the morphological difficulty score.</li></ul><p id="index-p-d46e749"><span class="numberParagraph">4</span>In addition, we also calculated the number of words in each document, even if in our case, it cannot be interpreted as a criterion for determining readability since it is largely determined by the type of document. E.g., the documents belonging to the subcorpus of newspapers contain individual articles and are therefore short, while the subcorpus of computer magazines contains entire magazines which are considerably longer.</p></section><section class="teidiv0" id="index-body.1_div.6"><header><h2><span class="headingNumber">6. </span><span class="head" itemprop="head">Analysis of Slovene Texts</span></h2></header><p id="index-p-d46e752"><span class="numberParagraph">1</span>In this section, we describe the methodology used for our analysis. In the first subsection, we describe the data sets on which we conducted our analysis. In the second subsection, we describe how we constructed the list of easy words used in some of the readability measures.</p><div class="teidiv1" id="index-body.1_div.6_div.1"><h3><span class="headingNumber">6.1. </span><span class="head" itemprop="head">Data Sets</span></h3><p id="index-p-d46e755"><span class="numberParagraph">1</span>We created a set of subcorpora from the Gigafida reference corpus of written Slovene (<span class="ref" itemprop="ref">Logar et al. 2012</span>). Gigafida contains 39,427 Slovene texts released from 1990 to 2011, for a total of 1,187,002,502 words. We focused on texts published in magazines, newspapers, and books while ignoring texts collected from the internet. The texts in the Gigafida corpus are segmented into paragraphs and sentences, tokenized, and part-of-speech tagged using the Obeliks tagger (<a class="link_ref" itemprop="ref" href="#Gr%C4%8Dar.2012" title="Grčar Miha Simon Krek and Kaja Dobrovoljc. 2012. Obeliks statisticni oblikoskladenjski oznacevalnik in lematizator za slovenski...">Grčar et al. 2012</a>). We grouped the texts based on the intended audience, resulting in the following subcorpora:</p><ul itemprop="list"><li class="item" itemprop="item" id="d46e763"><span style="font-weight:bold" itemprop="hi">Children's magazines</span> include magazines aimed at younger children (to be read independently or by their parents), namely Cicido and Ciciban.</li><li class="item" itemprop="item" id="d46e767"><span style="font-weight:bold" itemprop="hi">Pop magazines</span> contain magazines aimed at the general public, namely Lisa, Gloss, and Stop.</li><li class="item" itemprop="item" id="d46e771"><span style="font-weight:bold" itemprop="hi">Newspapers</span> contain general adult population newspapers, namely Delo and Dolenjski list.</li><li class="item" itemprop="item" id="d46e775"><span style="font-weight:bold" itemprop="hi">Computer magazines</span> include magazines focusing on technical topics relating to computers, namely Monitor, Računalniške novice, PC &amp; Mediji, and Moj Mikro.</li><li class="item" itemprop="item" id="d46e779"><span style="font-weight:bold" itemprop="hi">National Assembly</span> includes transcriptions of sessions from the National Assembly of Slovenia.</li></ul><p id="index-p-d46e783"><span class="numberParagraph">2</span>In Table 1 we show the number of documents in each subcorpus and the average number of words per document. The subcorpus of newspapers contains the largest number of documents, while the subcorpus of text sourced from the National Assembly of Slovenia contains the fewest.</p><div class="table-scroll" itemprop="table"><table><caption>Table 1: The number of documents and the average number of words per document for each subcorpus.</caption><thead><tr itemprop="row"><th>Subcorpus</th><th style="text-align:right;">#docs</th><th style="text-align:right;">Avg. #words / doc</th><th style="text-align:right;">Total #words</th></tr></thead><tbody><tr itemprop="row"><td>Children's magazines</td><td style="text-align:right;">125</td><td style="text-align:right;">5,488</td><td style="text-align:right;">686,000</td></tr><tr itemprop="row"><td>Pop magazines</td><td style="text-align:right;">247</td><td style="text-align:right;">33,967</td><td style="text-align:right;">8,389,849</td></tr><tr itemprop="row"><td>Newspapers</td><td style="text-align:right;">14,011</td><td style="text-align:right;">12,881</td><td style="text-align:right;">180,475,691</td></tr><tr itemprop="row"><td>Computer magazines</td><td style="text-align:right;">163</td><td style="text-align:right;">110,875</td><td style="text-align:right;">18,072,625</td></tr><tr itemprop="row"><td>National Assembly</td><td style="text-align:right;">35</td><td style="text-align:right;">58,841</td><td style="text-align:right;">2,059,435</td></tr></tbody></table></div><p id="index-p-d46e834"><span class="numberParagraph">3</span>Our hypothesis is that the readability measures will be able to distinguish texts from different subcorpora. We assume that children's magazines will be easily distinguishable from other genres that are addressing an adult population. We also suppose that general magazines are less complex than specialized magazines. The National Assembly transcripts were included as they differ from other texts in two major ways: a.) they are transcripts of spoken language and b.) they relate to a highly technical subject matter. Because of this, we were interested in how readability measures would grade them. To test our hypothesis and to determine how well each readability measure works, we analyzed texts from each subcorpus to obtain a score distribution for each measure. The scores were calculated separately for each source text (e.g., one magazine article, a newspaper, or one assembly session).</p></div><div class="teidiv1" id="index-body.1_div.6_div.2"><h3><span class="headingNumber">6.2. </span><span class="head" itemprop="head">List of Common Words</span></h3><p id="index-p-d46e837"><span class="numberParagraph">1</span>For designing the list of common words, we took a corpus-based approach. Note that the methodology to create a list of common words from language corpora was already tested for other languages, (see e.g., <a class="link_ref" itemprop="ref" href="#Kilgarriff.2014" title="Kilgarriff Adam Frieda Charalabopoulou Maria Gavrilidou Janne Bondi Johannessen Saussan Khalil Sofie Johansson Kokkinakis Rober...">Kilgarriff et al. 2014</a>). We used four corpora to create a list of common words: Kres, Janes, Gos, and Šolar:</p><ul itemprop="list"><li class="item" itemprop="item" id="d46e843"><span style="font-weight:bold" itemprop="hi">Šolar</span> (<a class="link_ref" itemprop="ref" href="#Kosem.2011" title="Kosem Iztok Tadeja Rozman and Mojca Stritar. 2011. How do Slovenian primary and secondary school students write and what their ...">Kosem et al. 2011</a>) contains 2,703 texts written by pupils in Slovenia from grades 6 to 13 (grade 6 to 9 in primary school, and grade 1 to 4 in secondary school). The texts include essays, summaries, and answers to examination questions.</li><li class="item" itemprop="item" id="d46e850"><span style="font-weight:bold" itemprop="hi">Gos</span> (<a class="link_ref" itemprop="ref" href="#Verdonik.2011" title="Verdonik Darinka Ana Zwitter Vitez and Hotimir Tivadar. 2011. Slovenski govorni korpus Gos. Trojina zavod za uporabno slovenist...">Verdonik et al. 2011</a>) contains around 120 hours of recorded spoken Slovene (1,035,101 words), as well as transcriptions of the recordings. The recordings are collected from a variety of sources, including conversations, television, radio, and phone calls. Around 10% of the corpus consists of recorded lessons in primary and secondary schools.</li><li class="item" itemprop="item" id="d46e857"><span style="font-weight:bold" itemprop="hi">Janes</span> (<a class="link_ref" itemprop="ref" href="#Fi%C5%A1er.2014" title="Fišer Darja Tomaž Erjavec Ana Zwitter Vitez and Nikola Ljubešić. 2014. JANES se predstavi metode orodja in viri za nestandardno...">Fišer et al. 2014</a>) contains Slovene texts from various internet sources, such as tweets, forum posts, blogs, comments, and Wikipedia talk pages.</li><li class="item" itemprop="item" id="d46e865"><span style="font-weight:bold" itemprop="hi">Kres</span> (<a class="link_ref" itemprop="ref" href="#LogarBerginc.2009" title="Logar Berginc Nataša and Simon Šuster. 2009. Gradnja novega korpusa slovenščine. Jezik in slovstvo 54 5768.">Logar Berginc and Šuster 2009</a>) is a sub-corpus of Gigafida that is balanced with respect to the source (e.g. newspapers, magazines, or internet).</li></ul><p id="index-p-d46e873"><span class="numberParagraph">2</span>We extracted the most common words and defined the common words as the ones that appear frequently in all four corpora (and are therefore not specific to a certain text type). We use four corpora to include texts that primarily reflect language production by different language users (Gos, Janes, Šolar), as well as texts that primarily reflect standard language (Kres). We aimed at covering younger school-going population (Šolar) and adults. For some corpora, we could have assigned words to different age levels (e.g. using pupils' grade levels in Šolar or using the age groups available in Gos metadata), but these corpora are very specific and the resulting word groups would mainly reflect the genre instead of age levels. Because of this, we opted for the approach of crossing the word lists to obtain a single list. The overlap of the most common words in four corpora eliminates frequent words which are typical for only one of the corpora (e.g. administrative language in Kres, spoken language markers in Gos, Twitter-specific usage in Janes, and literary references from essays in Šolar).</p><p id="index-p-d46e874"><span class="numberParagraph">3</span>From each corpus, we extracted the 10,000 most frequent word lemmas and part-of-speech tuples. In order to construct a list of common words representative of Slovene language, we selected the word lemmas that occurred in the most frequent word lists of all the four corpora. We obtained a list of 2,562 common words, which we used in readability measures.</p></div></section><section class="teidiv0" id="index-body.1_div.7"><header><h2><span class="headingNumber">7. </span><span class="head" itemprop="head">Results</span></h2></header><p id="index-p-d46e877"><span class="numberParagraph">1</span>For each text in each subcorpus, we calculated readability scores using all readability measures described in the previous section. In Figure 1 we present a few examples of obtained score distributions. We show distributions for three text subcorpora (children’s magazines, newspapers, and technical magazines) and three readability scores (Goobledygook, Coleman-Liau, and the average number of words in a sentence).</p><figure class="figure" itemprop="figure"><figcaption class="caption" itemprop="head"><b></b>Figure 1: The score distributions for three text subcorpora and three readability measures. The distributions show that technical magazines readability scores are the most consistent, while newspapers' scores are more diverse. Children's magazines' scores have a strong peak on the left-hand side (easier texts) that is well separated from the other sources.</figcaption><img src="fig_dist.png" alt="Figure 1: The score distributions for three text subcorpora and three&#xA;                        readability measures. The distributions show that technical magazines&#xA;                        readability scores are the most consistent, while newspapers' scores are&#xA;                        more diverse. Children's magazines' scores have a strong peak on the&#xA;                        left-hand side (easier texts) that is well separated from the other&#xA;                        sources." class="graphic" itemprop="graphic" style=" height:600px;" /></figure><p id="index-p-d46e881"><span class="numberParagraph">2</span>To show a compact overview of all included readability measures we calculated the median, first and third quartiles of the distribution for each score and each text subcorpus. The box-and-whiskers plots showing these results are visualized in Figure 2 which shows that most readability measures are able to distinguish between different subcorpora. Additionally, some of the readability measures confirm our original hypothesis, i.e. they are able to distinguish children's magazines from other genres that are addressing adult population, and evaluate general magazines as less complex than computer magazines.</p><figure class="figure" itemprop="figure"><figcaption class="caption" itemprop="head"><b></b>Figure 2: The scores of each readability measure for each subcorpus of texts, represented with box plots. The subcorpora depicted from left to right are: 1.) Children's magazines, 2.) General magazines, 3.) Newspapers, 4.) Computer magazines, and 5.) National assembly transcriptions. The boxes show the first, second, and third quartile of the distributions while the whiskers extend for 1.5 IQR past the first and third quartile.</figcaption><img src="fig_bar_plots.png" alt="Figure 2: The scores of each readability measure for each subcorpus of&#xA;                        texts, represented with box plots. The subcorpora depicted from left to&#xA;                        right are: 1.) Children's magazines, 2.) General magazines, 3.) Newspapers,&#xA;                        4.) Computer magazines, and 5.) National assembly transcriptions. The boxes&#xA;                        show the first, second, and third quartile of the distributions while the&#xA;                        whiskers extend for 1.5 IQR past the first and third quartile." class="graphic" itemprop="graphic" style=" height:1600px;" /></figure><p id="index-p-d46e885"><span class="numberParagraph">3</span>Figure 2 allows for an additional interpretation of readability measures. For example, children's magazines vs. general magazines vs. newspapers mean scores show increasing complexity in the following measures: Percentage of long words, Flesh Kincaid Grade Level, Gunning Fog Index, Dale-Chall Readability Formula (based on complexity defined by syllables), Context of Difficult Words, SMOG, LIX, RIX and Automated Readability Index. All these measures consider the length of words and/or sentences. The percentage of adjectives also seems to correlate with the complexity of these three text types, although to a lesser extent. The same holds for Flesh Reading Ease, since higher scores indicate lower complexity. For the majority of these measures, the distinction between newspapers and specialized computer magazines is either less evident or not evident at all, but they do indicate that computer magazines are less readable than general magazines. </p><p id="index-p-d46e886"><span class="numberParagraph">4</span>Scores using the list of common words do not lead to the same conclusions. Percentage of Difficult Words and Dale-Chall Readability Formula with word list do not reflect the complexity of genres, but to some extent, they do distinguish between general and specialized texts (i.e. newspapers and general magazines have lower scores than specialized computer magazines). One of the reasons for the relatively high scores for the complexity of children magazines might be in the large proportion of literary language, such as in poems for children with many words not in the list of common words. For example, “KRAH, KRAH, KRAH! MENE NIČ NI STRAH!” (Krah, krah, krah! I am not afraid!) has 7 words, out of which 4 are on the list of simple words, while the interjection KRAH is not on the simple words list. Therefore, the proportion of difficult words in this segment is 42.8% (3 occurrences of word KRAH out of 7 words in total). On the other hand, the words are short, therefore length-based measures consider them to be simple words.</p><p id="index-p-d46e887"><span class="numberParagraph">5</span>The readability scores for the National Assembly subcorpus show high variability across the measures, which might be attributed to the fact that it is a different genre (spoken, but specialized). E.g., in several measures where the readability complexity rises from children's magazines to general magazines and newspapers, the National assembly scores are close to general magazines. Very long words are less likely used in spoken language, even in a political context. Average morphological difficulty and context of difficult words lead to the interpretation that this genre is more complex (less “readable”). The very high score for the context of difficult words might be attributed to enumeration of Assembly members (e.g., “Obveščen sem, da so zadržani in se današnje seje ne morejo udeležiti naslednje poslanke in poslanci: Ciril Pucko, Franc Kangler, Vincencij Demšar, Branko Kalalemina, ...” (I was informed that the following deputies are occupied and cannot attend this session: …). The relatively high percentage of verbs can also be interpreted from this perspective, e.g., the National assembly text include many performatives, such as “Pričenjam nadaljevanje seje” (Starting the continuation of the session) and “Ugotavljamo prisotnost v dvorani” (Establishing the presence).</p><p id="index-p-d46e888"><span class="numberParagraph">6</span>In summary, using a list of common words did not improve the partitioning of the text subcorpora perceived as easy and as difficult to read. Both measures that use it (Dale-Chall and Spache readability formulas) are poor separators. A number of simple readability measures worked well, such as the percentage of long words, the percentage of verbs/adjectives, and the average morphological difficulty.</p><p id="index-p-d46e889"><span class="numberParagraph">7</span>We also calculated the sample mean and standard deviation of readability measures for each text subcorpus. The results are shown in Table 2.</p><div class="table-scroll" itemprop="table"><table><caption>Table 2: The mean and standard deviation for each subcorpus of texts and each readability score.</caption><tr itemprop="row"><th>Measure</th><th>Children's mag.</th><th>Magazines</th><th>Newspapers</th><th>Technical mag.</th><th>National assembly</th></tr><tr itemprop="row"><td>% long words</td><td>0.065 (0.015)</td><td>0.109 (0.011)</td><td>0.137 (0.029)</td><td>0.146 (0.010)</td><td>0.137 (0.046)</td></tr><tr itemprop="row"><td>Number of words</td><td>5488 (6184)</td><td>33966 (34821)</td><td>12881 (84708)</td><td>110875 (151007)</td><td>58841 (106515)</td></tr><tr itemprop="row"><td>% adjectives</td><td>0.078 (0.016)</td><td>0.111 (0.013)</td><td>0.120 (0.020)</td><td>0.120 (0.008)</td><td>0.096 (0.022)</td></tr><tr itemprop="row"><td>% verbs</td><td>0.216 (0.026)</td><td>0.170 (0.015)</td><td>0.161 (0.034)</td><td>0.144 (0.013)</td><td>0.180 (0.044)</td></tr><tr itemprop="row"><td>% unique words</td><td>0.517 (0.077)</td><td>0.375 (0.053)</td><td>0.513 (0.114)</td><td>0.244 (0.144)</td><td>0.277 (0.173)</td></tr><tr itemprop="row"><td>Context of difficult words</td><td>0.756 (0.054)</td><td>0.834 (0.027)</td><td>0.849 (0.133)</td><td>0.808 (0.036)</td><td>0.929 (0.044)</td></tr><tr itemprop="row"><td>% difficult words</td><td>0.464 (0.048)</td><td>0.369 (0.022)</td><td>0.356 (0.122)</td><td>0.389 (0.032)</td><td>0.280 (0.036)</td></tr><tr itemprop="row"><td>Gunning Fog Index</td><td>9.950 (1.255)</td><td>14.272 (1.271)</td><td>18.662 (9.319)</td><td>17.470 (0.800)</td><td>15.901 (3.493)</td></tr><tr itemprop="row"><td>Flesch reading ease</td><td>37.592 (4.989)</td><td>23.855 (5.217)</td><td>10.002 (24.128)</td><td>12.520 (4.340)</td><td>19.178 (13.098)</td></tr><tr itemprop="row"><td>Flesch–Kincaid grade level</td><td>10.500 (0.894)</td><td>13.596 (1.193)</td><td>17.356 (8.959)</td><td>15.999 (0.741)</td><td>14.523 (2.761)</td></tr><tr itemprop="row"><td>Dale–Chall</td><td>2.845 (0.425)</td><td>4.036 (0.306)</td><td>4.972 (1.270)</td><td>4.941 (0.258)</td><td>4.560 (0.971)</td></tr><tr itemprop="row"><td>Dale–Chall with word list</td><td>7.781 (0.720)</td><td>6.534 (0.357)</td><td>6.643 (2.163)</td><td>6.955 (0.484)</td><td>5.208 (0.539)</td></tr><tr itemprop="row"><td>Spache readability formula</td><td>6.217 (0.368)</td><td>6.079 (0.348)</td><td>6.977 (3.499)</td><td>6.685 (0.323)</td><td>5.482 (0.600)</td></tr><tr itemprop="row"><td>Automated readability index</td><td>12.873 (1.086)</td><td>16.117 (1.428)</td><td>20.474 (11.456)</td><td>19.007 (0.885)</td><td>17.014 (3.371)</td></tr><tr itemprop="row"><td>SMOG</td><td>12.206 (0.759)</td><td>15.095 (1.066)</td><td>18.200 (2.757)</td><td>17.194 (0.611)</td><td>15.849 (2.500)</td></tr><tr itemprop="row"><td>LIX</td><td>33.676 (3.384)</td><td>44.999 (3.282)</td><td>56.016 (23.123)</td><td>53.260 (2.077)</td><td>47.909 (9.073)</td></tr><tr itemprop="row"><td>RIX</td><td>2.381 (0.496)</td><td>4.481 (0.781)</td><td>7.370 (3.836)</td><td>6.354 (0.518)</td><td>5.250 (2.574)</td></tr><tr itemprop="row"><td>Coleman-Liau index</td><td>17.785 (1.120)</td><td>19.823 (0.861)</td><td>21.220 (1.807)</td><td>21.762 (0.903)</td><td>20.318 (2.170)</td></tr><tr itemprop="row"><td>Avg. morphological difficulty</td><td>0.419 (0.017)</td><td>0.428 (0.010)</td><td>0.436 (0.044)</td><td>0.441 (0.017)</td><td>0.445 (0.026)</td></tr><tr itemprop="row"><td>Avg. sentence length</td><td>8.353 (0.820)</td><td>13.389 (2.843)</td><td>21.120 (4.043)</td><td>18.641 (1.960)</td><td>19.063 (3.826)</td></tr></table></div><p id="index-p-d46e1041"><span class="numberParagraph">8</span>Using these results, we calculated the Bhattacharyya distance between the distributions of Children's magazines and newspapers for each score. The Bhattacharyya distance measures the similarity between two statistical distributions. We assumed the scores were distributed normally, as the results shown in Figure 1 show that the scores approximately follow a normal distribution, and calculated the distance using the following formula: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mrow><mi>D</mi></mrow><mrow><mi>B</mi></mrow></msub><mfenced separators="|"><mrow><mi>p</mi><mo>,</mo><mi></mi><mi>q</mi></mrow></mfenced><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mn>4</mn></mrow></mfrac><mrow><mrow><mi mathvariant="normal">ln</mi></mrow><mo>⁡</mo><mrow><mfenced open="[" close="]" separators="|"><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mn>4</mn></mrow></mfrac><mfenced separators="|"><mrow><mfrac><mrow><msubsup><mrow><mi>σ</mi></mrow><mrow><mi>p</mi></mrow><mrow><mn>2</mn></mrow></msubsup></mrow><mrow><msubsup><mrow><mi>σ</mi></mrow><mrow><mi>q</mi></mrow><mrow><mn>2</mn></mrow></msubsup></mrow></mfrac><mo>+</mo><mfrac><mrow><msubsup><mrow><mi>σ</mi></mrow><mrow><mi>q</mi></mrow><mrow><mn>2</mn></mrow></msubsup></mrow><mrow><msubsup><mrow><mi>σ</mi></mrow><mrow><mi>p</mi></mrow><mrow><mn>2</mn></mrow></msubsup></mrow></mfrac><mo>+</mo><mn>2</mn></mrow></mfenced></mrow></mfenced><mo>+</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mn>4</mn></mrow></mfrac><mfenced separators="|"><mrow><mfrac><mrow><msup><mrow><mfenced separators="|"><mrow><msub><mrow><mi>μ</mi></mrow><mrow><mi>p</mi></mrow></msub><mo>-</mo><msub><mrow><mi>μ</mi></mrow><mrow><mi>q</mi></mrow></msub></mrow></mfenced></mrow><mrow><mn>2</mn></mrow></msup></mrow><mrow><msubsup><mrow><mi>σ</mi></mrow><mrow><mi>p</mi></mrow><mrow><mn>2</mn></mrow></msubsup><mo>+</mo><msubsup><mrow><mi>σ</mi></mrow><mrow><mi>q</mi></mrow><mrow><mn>2</mn></mrow></msubsup></mrow></mfrac></mrow></mfenced></mrow></mrow></math></p><p id="index-p-d46e1160"><span class="numberParagraph">9</span>We also show the Bhattacharyya coefficient, which measures the overlap between two statistical distributions and can be calculated as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>BC</mi><mfenced separators="|"><mrow><mi>p</mi><mo>,</mo><mi></mi><mi>q</mi></mrow></mfenced><mo>=</mo><msup><mrow><mi>e</mi></mrow><mrow><mo>(</mo><mo>-</mo><msub><mrow><mi>D</mi></mrow><mrow><mi>B</mi></mrow></msub><mfenced separators="|"><mrow><mi>p</mi><mo>,</mo><mi></mi><mi>q</mi></mrow></mfenced><mo>)</mo></mrow></msup></math></p><p id="index-p-d46e1194"><span class="numberParagraph">10</span>The results are presented in Table 3. These results are similar to the ones shown in Figure 2, with the readability formulas using the list of difficult words showing less dichotomization power. The largest distance is obtained using average sentence lengths.</p><div class="table-scroll" itemprop="table"><table><caption>Table 3: The Bhattacharyya distances and coefficients between the distributions of scores for children's magazines and newspapers for each readability measure. The results are sorted by decreasing distance.</caption><tr itemprop="row"><th>Measure</th><th>Distance</th><th>Coefficient</th></tr><tr itemprop="row"><td>Average sentence length</td><td><span style="font-weight:bold" itemprop="hi">2.866</span></td><td><span style="font-weight:bold" itemprop="hi">0.057</span></td></tr><tr itemprop="row"><td>SMOG</td><td>1.433</td><td>0.239</td></tr><tr itemprop="row"><td>% long words</td><td>1.350</td><td>0.259</td></tr><tr itemprop="row"><td>RIX</td><td>1.101</td><td>0.333</td></tr><tr itemprop="row"><td>Flesch-Kincaid grade level</td><td>0.956</td><td>0.385</td></tr><tr itemprop="row"><td>Automated readability index</td><td>0.945</td><td>0.389</td></tr><tr itemprop="row"><td>Dale-Chall readability formula</td><td>0.885</td><td>0.413</td></tr><tr itemprop="row"><td>Gunning fog index</td><td>0.880</td><td>0.415</td></tr><tr itemprop="row"><td>LIX</td><td>0.853</td><td>0.426</td></tr><tr itemprop="row"><td>Spache readability formula</td><td>0.797</td><td>0.451</td></tr><tr itemprop="row"><td>Flesch reading ease</td><td>0.776</td><td>0.460</td></tr><tr itemprop="row"><td>% adjectives</td><td>0.719</td><td>0.487</td></tr><tr itemprop="row"><td>Coleman-Liau index</td><td>0.708</td><td>0.493</td></tr><tr itemprop="row"><td>% verbs</td><td>0.432</td><td>0.649</td></tr><tr itemprop="row"><td>% difficult words</td><td>0.365</td><td>0.694</td></tr><tr itemprop="row"><td>Dale-Chall with word list</td><td>0.318</td><td>0.728</td></tr><tr itemprop="row"><td>Context of difficult words</td><td>0.285</td><td>0.752</td></tr><tr itemprop="row"><td>Avg. morphological difficulty</td><td>0.235</td><td>0.790</td></tr><tr itemprop="row"><td>% unique words</td><td>0.039</td><td>0.961</td></tr></table></div></section><section class="teidiv0" id="index-body.1_div.8"><header><h2><span class="headingNumber">8. </span><span class="head" itemprop="head">Additional Statistical Tests</span></h2></header><p id="index-p-d46e1284"><span class="numberParagraph">1</span>In addition to the initial analysis presented in the previous section, we performed additional, more thorough statistical tests to determine which of the evaluated measures are better at predicting the group a text belongs to. We used the following approaches:</p><ul itemprop="list"><li class="item" itemprop="item" id="d46e1286"><span style="font-weight:bold" itemprop="hi">Mutual information.</span> This measure reports the amount of information we get about a random variable <span style="font-style:italic" itemprop="hi">Y</span> by observing another random variable <span style="font-style:italic" itemprop="hi">X</span>. In our case, mutual information reports the amount of information we get about the group of texts by knowing a score of certain readability measure. Mutual information is defined as: <math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mo>∑</mo><mrow><mi>y</mi><mo>∈</mo><mi>Y</mi></mrow></msub><mrow><msub><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></msub><mrow><mi>p</mi><mfenced separators="|"><mrow><mi>x</mi><mo>,</mo><mi></mi><mi>y</mi></mrow></mfenced><mi>l</mi><mi>o</mi><mi>g</mi><mfenced separators="|"><mrow><mfrac><mrow><mi>p</mi><mfenced separators="|"><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow></mfenced></mrow><mrow><mi>p</mi><mfenced separators="|"><mrow><mi>x</mi></mrow></mfenced><mi>p</mi><mfenced separators="|"><mrow><mi>y</mi></mrow></mfenced></mrow></mfrac></mrow></mfenced></mrow></mrow><mtext>,</mtext></math> where p(x) and p(y) are the marginal probability distribution functions of <span style="font-style:italic" itemprop="hi">X</span> and <span style="font-style:italic" itemprop="hi">Y</span> and p(x, y) is the joint probability function of <span style="font-style:italic" itemprop="hi">X</span> and <span style="font-style:italic" itemprop="hi">Y.</span> In our case, X represents the distributions of readability measures and Y the distribution of groups. The higher the mutual information between the readability measure and the groups, the more useful the measure for determining the group membership.</li><li class="item" itemprop="item" id="d46e1358"><span style="font-weight:bold" itemprop="hi">Analysis of variance (ANOVA). </span>This measure first splits samples of a statistical distribution into several groups (in our case, based on the group the texts belong to) and then calculates if the groups are significantly different from one another. We use this measure to determine if the distributions obtained by calculating a single measure on each group of texts are significantly different. If they are, they can be useful for determining the group membership of a given text.</li><li class="item" itemprop="item" id="d46e1362"><span style="font-weight:bold" itemprop="hi">Feature selection using a chi-squared test.</span> Similarly to mutual information, we use the chi-squared test to determine whether the readability measures and the group memberships are mutually dependent. If they are, this indicates that knowing the value of the readability measure is useful when determining which group a text belongs to.</li></ul><p id="index-p-d46e1366"><span class="numberParagraph">2</span>In addition to the four statistical tests used above, we also ranked each feature using a random forest classifier (<a class="link_ref" itemprop="ref" href="#Breiman.2001" title="Breiman Leo. 2001. Random forests. Machine learning 45 No. 1 532.">Breiman 2001</a>). The classifier is capable of automatically combining different readability measures in order to predict which subcorpus a given text belongs to and is also capable of calculating how important each readability measure was when making the prediction. The classifier is described in more detail in the next section. Using each of these tests, we obtained scores that tell us how useful each readability measure is when trying to predict the subcorpus it came from. The results are presented in Table 4, with higher scores indicating better (more informative) readability measures.</p><div class="table-scroll" itemprop="table"><table><caption>Table 4: The ranks of readability measures obtained by the statistical tests, which report the usefulness of readability measures for predicting group membership. The measures are ordered from the most useful to the least useful.</caption><tr itemprop="row"><th>Random Forest</th><th>ANOVA</th><th>Mutual information</th><th>Chi2</th></tr><tr itemprop="row"><td>Average sentence length</td><td>Average sentence length</td><td>Average sentence length</td><td>% new words</td></tr><tr itemprop="row"><td>% new words</td><td>% difficult words SPG</td><td>RIX</td><td>Number of words</td></tr><tr itemprop="row"><td>Number of words</td><td>% long words</td><td>SMOG</td><td>% unique words</td></tr><tr itemprop="row"><td>% unique words</td><td>SMOG</td><td>Percentage of new words</td><td>Flesch reading ease</td></tr><tr itemprop="row"><td>% difficult words SPG</td><td>Dale-Chall</td><td>Automated readability index</td><td>LIX</td></tr><tr itemprop="row"><td>Gunning fog index</td><td>Percentage of adjectives</td><td>Gunning fog index</td><td>Average sentence length</td></tr><tr itemprop="row"><td>Percentage of verbs</td><td>Coleman-Liau index</td><td>LIX</td><td>% difficult words</td></tr><tr itemprop="row"><td>RIX</td><td>Percentage of unique words</td><td>Number of words</td><td>Gunning fog index</td></tr><tr itemprop="row"><td>Dale-Chall (word list)</td><td>RIX</td><td>Flesch-Kincaid grade level</td><td>Automated readability index</td></tr><tr itemprop="row"><td>SMOG</td><td>% verbs</td><td>Flesch reading ease</td><td>% difficult words SPG</td></tr><tr itemprop="row"><td>LIX</td><td>Flesch reading ease</td><td>Dale-Chall</td><td>Flesch-Kincaid grade level</td></tr><tr itemprop="row"><td>Flesch-Kincaid grade level</td><td>Context of difficult words</td><td>% unique words</td><td>SMOG</td></tr><tr itemprop="row"><td>Context of difficult words</td><td>LIX</td><td>% long words</td><td>RIX</td></tr><tr itemprop="row"><td>Dale-Chall</td><td>Gunning fog index</td><td>% difficult words</td><td>Coleman-Liau index</td></tr><tr itemprop="row"><td>% long words</td><td>Flesch-Kincaid grade level</td><td>% difficult words SPG</td><td>Dale-Chall</td></tr><tr itemprop="row"><td>% difficult words</td><td>% difficult words</td><td>Spache readability formula</td><td>Spache readability formula</td></tr><tr itemprop="row"><td>Avg morphological difficulty</td><td>Automated readability index</td><td>Context of difficult words</td><td>Dale-Chall (word list)</td></tr><tr itemprop="row"><td>Automated readability index</td><td>% new words</td><td>Coleman-Liau index</td><td>% long words</td></tr><tr itemprop="row"><td>% adjectives</td><td>Number of words</td><td>% verbs</td><td>Context of difficult words</td></tr><tr itemprop="row"><td>Flesch reading ease</td><td>Dale-Chall (word list)</td><td>% adjectives</td><td>% verbs</td></tr><tr itemprop="row"><td>Spache readability formula</td><td>Spache readability formula</td><td>Dale-Chall (word list)</td><td>% adjectives</td></tr><tr itemprop="row"><td>Coleman-Liau index</td><td>Avg morphological difficulty</td><td>Avg morphological difficulty</td><td>Avg morphological difficulty</td></tr></table></div><p id="index-p-d46e1490"><span class="numberParagraph">3</span>The results of the statistical tests show that the features commonly used by the readability formulas (i.e. an average sentence length and number of long words) are useful when it comes to determining group membership. In particular, the average sentence length stands out since it is ranked as the most important measure in three out of the four tests. At least one of either LIX or RIX is also highly ranked (in the top 50% of all measures) by all the tests. Those measures are the only ones from the tested measures that were not designed specifically for English, which could be one of the reasons why they perform better on Slovene texts. The results also show that a number of proposed simpler readability criteria, such as the percentage of verbs, percentage of adjectives, and the average morphological difficulty are less useful than the established statistical formulas. The results are inconclusive about the most useful readability criterion for Slovene. Several formulas and statistics are useful, but the rankings are different by different tests. When using our list of common words Dale-Chall and Spache readability formulas are again shown to perform worse than the formulas that consider long words as difficult.</p></section><section class="teidiv0" id="index-body.1_div.9"><header><h2><span class="headingNumber">9. </span><span class="head" itemprop="head">Classification Results</span></h2></header><p id="index-p-d46e1493"><span class="numberParagraph">1</span>In addition to statistical evaluation, we also performed a test with machine learning classifiers (<a class="link_ref" itemprop="ref" href="#Kononenko.2007" title="Kononenko Igor and Matjaž Kukar. 2007. Machine learning and data mining. Chichester Horwood Publishing.">Kononenko and Kukar 2007</a>) to see whether we could use our readability measures to predict which subcorpus a text belongs to. With classification models, we can automatically learn how to split the texts into different subcorpora based on readability formulas and other readability criteria. We used the following classification models.</p><ul itemprop="list"><li class="item" itemprop="item" id="d46e1499"><span style="font-weight:bold" itemprop="hi">Decision trees</span> construct a binary decision tree where each node splits the training set based on one readability measure. The trained tree can predict the subcorpus of a given text.</li><li class="item" itemprop="item" id="d46e1503"><span style="font-weight:bold" itemprop="hi">Random forests (<a class="link_ref" itemprop="ref" href="#Breiman.2001" title="Breiman Leo. 2001. Random forests. Machine learning 45 No. 1 532.">Breiman 2001</a>)</span> create multiple decision trees in a random manner. This reduces the variance of a model and often gives better prediction accuracy than using a single decision tree.</li><li class="item" itemprop="item" id="d46e1510"><span style="font-weight:bold" itemprop="hi">Naive Bayes</span> is a probabilistic model based on the Bayes’ theorem. The model assumes that the readability measures are independent.</li><li class="item" itemprop="item" id="d46e1514"><span style="font-weight:bold" itemprop="hi">Extreme gradient boosting (<a class="link_ref" itemprop="ref" href="#Chen.2016" title="Chen Tianqi and Carlos Guestrin. 2016. Xgboost A scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD internati...">Chen and Carlos 2016</a>)</span> constructs a large number of simple classifiers and combines them to achieve state-of-the-art results on many classification problems.</li></ul><p id="index-p-d46e1521"><span class="numberParagraph">2</span>In order to use classification models, we first train them on a training subset of our data set. We used randomly selected 75% of our data set for the training. To evaluate the models, we calculated the classification accuracy (i.e. the percentage of texts each model predicted correctly) on the remaining 25% of the data set. The obtained results are presented in Table 5. The results obtained by the majority classifier (i.e. classifying everything as the most frequent group) are presented as a baseline score.</p><div class="table-scroll" itemprop="table"><table><caption>Table 5: The classification accuracies for each of the models. The numbers show the percentage of texts for which the group membership was correctly predicted.</caption><tr itemprop="row"><th>Model</th><th>Classification Accuracy</th></tr><tr itemprop="row"><td>Random Forest</td><td><span style="font-weight:bold" itemprop="hi">0.984</span></td></tr><tr itemprop="row"><td>Extreme Gradient Boosting</td><td>0.979</td></tr><tr itemprop="row"><td>Decision Tree</td><td>0.960</td></tr><tr itemprop="row"><td>Majority Classifier</td><td>0.791</td></tr><tr itemprop="row"><td>Naive Bayes</td><td>0.553</td></tr></table></div><p id="index-p-d46e1544"><span class="numberParagraph">3</span>Table 5 shows that we are able to predict the correct group of a text with high accuracy, over 98% with the best-performing model (Random forest). This shows that a combination of readability measures that we evaluated in this paper can be used to accurately distinguish between different groups of text.</p></section><section class="teidiv0" id="index-body.1_div.10"><header><h2><span class="headingNumber">10. </span><span class="head" itemprop="head">Conclusion and Future Work</span></h2></header><p id="index-p-d46e1547"><span class="numberParagraph">1</span>We analyzed statistical distributions of well-known readability measures on Slovene texts. We extracted five subcorpora of texts from the Gigafida corpus with commonly perceived different readability levels: children magazines, popular magazines, newspapers, technical magazines, and national assembly texts. We find that the readability formulas are able to distinguish between these subcorpora reasonably well, with the exception of national assembly texts, which are of a different, spoken, genre and the used measures were not originally designed to handle it. A number of simple readability statistics, such as the context of difficult words and average sentence length, also dichotomize the different subcorpora of text.</p><p id="index-p-d46e1548"><span class="numberParagraph">2</span>In this work, we only focused on simple readability formulas along with some additional readability criteria. There exist several more complex methods for evaluating the complexity of texts, such as the one presented in <a class="link_ref" itemprop="ref" href="#Lu.2009" title="Lu Xiaofei. 2009. Automatic measurement of syntactic complexity in child language acquisition. International Journal of Corpus ...">Lu (2009)</a> and <a class="link_ref" itemprop="ref" href="#Wiersma.2010" title="Wiersma Wybo John Nerbonne and Timo Lauttamus. 2010. Automatically extracting typical syntactic differences from corpora. Liter...">Wiersma et al. (2010)</a>. Such advanced methods might be more suitable for Slovene texts than the simple methods used in this paper, and we plan to test them in future work.</p><p id="index-p-d46e1556"><span class="numberParagraph">3</span>Most of the used English readability formulas were designed to correlate with school grades and were initially tuned on that domain. For Slovene, there currently is no publicly available data set with texts tagged according to the appropriate grade level. This disallows analysis of the readability measures from this perspective. In future work, we plan to prepare such a corpus and design several readability scores fit for different purposes. This will allow us to frame text complexity as a classification problem with the goal of predicting the grade level of a text instead of predicting its group membership. In a similar approach, experts would annotate texts with readability scores. This would allow us to fit a regression model using the readability measures analyzed in this paper.</p><p id="index-p-d46e1557"><span class="numberParagraph">4</span>Another area that we plan to explore is the use of coherence and cohesion measures (<a class="link_ref" itemprop="ref" href="#Barzilay.2008" title="Barzilay Regina and Mirella Lapata. 2008. Modeling local coherence An entitybased approach. Computational Linguistics 34 No. 1 ...">Barzilay and Lapata 2008</a>; <a class="link_ref" itemprop="ref" href="#Crossley.2016" title="Crossley Scott A. Kristopher Kyle and Danielle S. McNamara. 2016. The tool for the automatic analysis of text cohesion (TAACO) ...">Crossley et al. 2016</a>), which are used to determine if words, sentences, and paragraphs are logically connected. Coherence and cohesion methods usually use machine learning approaches that mostly rely on language-specific features and shall be therefore evaluated on Slovene texts. The same applies to readability measures based on machine learning (<a class="link_ref" itemprop="ref" href="#Fran%C3%A7ois.2012" title="François Thomas and Eleni Miltsakaki. 2012. Do NLP and machine learning improve traditional readability formulas In Proceedings...">Francois and Miltsakaki 2012</a>) which we also plan to analyze in the future.</p></section><section class="teidiv0" id="index-body.1_div.11"><header><h2><span class="headingNumber">11. </span><span class="head" itemprop="head">Acknowledgments</span></h2></header><p id="index-p-d46e1570"><span class="numberParagraph">1</span>The research was financially supported by the Slovenian Research Agency through project J6-8256 (New grammar of contemporary standard Slovene: sources and methods), project J5-7387 (Influence of formal and informal corporate communications on capital markets), a young researcher grant, research core fundings no. P6-0411 and P2-0103; Republic of Slovenia, Ministry of Education, Science and Sport/European social fund/European fund for regional development/European cohesion fund (project Quality of Slovene textbooks, KaUč). This work has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 825153 (EMBEDDIA).</p></section></div><!--TEI back matter --><div class="tei_back"><section class="bibliography" id="index-back.1_div.1"><header><h2><span class="head" itemprop="head">Sources and literature</span></h2></header><ul>Literature:<li id="Anderson.1983" itemscope="" itemtype="https://schema.org/CreativeWork">Anderson, Jonathan. 1983. “LIX and RIX: Variations on a little-known readability index.” <span style="font-style:italic" itemprop="hi">Journal of Reading</span> 26, No. 6: 490-96.</li><li id="ArharHoldt.2009" itemscope="" itemtype="https://schema.org/CreativeWork">Arhar Holdt, Špela. 2009. “Učni korpus SSJ in leksikon besednih oblik za slovenščino.” <span style="font-style:italic" itemprop="hi">Jezik in slovstvo</span> 54, No. 3-4: 43-56.</li><li id="Bailin.2016" itemscope="" itemtype="https://schema.org/CreativeWork">Bailin, Alan, and Ann Grafstein. 2016. <span style="font-style:italic" itemprop="hi">Readability: Text and context</span>. Springer.</li><li id="Barzilay.2008" itemscope="" itemtype="https://schema.org/CreativeWork">Barzilay, Regina, and Mirella Lapata. 2008. “Modeling local coherence: An entity-based approach.” <span style="font-style:italic" itemprop="hi">Computational Linguistics</span> 34, No. 1: 1-34.</li><li id="Björnsson.1968" itemscope="" itemtype="https://schema.org/CreativeWork">Björnsson, Carl Hugo. 1968. <span style="font-style:italic" itemprop="hi">Läsbarhet</span>. Liber.</li><li id="Breiman.2001" itemscope="" itemtype="https://schema.org/CreativeWork">Breiman, Leo. 2001. “Random forests.” <span style="font-style:italic" itemprop="hi">Machine learning</span> 45, No. 1: 5-32.</li><li id="Chen.2016" itemscope="" itemtype="https://schema.org/CreativeWork">Chen, Tianqi, and Carlos Guestrin. 2016. “Xgboost: A scalable tree boosting system.” In <span style="font-style:italic" itemprop="hi">Proceedings of the 22</span><sup style="font-style:italic" itemprop="hi">nd</sup><span style="font-style:italic" itemprop="hi">  ACM SIGKDD international conference on knowledge discovery and data mining</span>, 785-794. ACM.</li><li id="Coleman.1975" itemscope="" itemtype="https://schema.org/CreativeWork">Coleman, Meri, and Ta Lin Liau. 1975. “A computer readability formula designed for machine scoring.” <span style="font-style:italic" itemprop="hi">Journal of Applied Psychology</span> 60, No. 2: 283.</li><li id="Crossley.2016" itemscope="" itemtype="https://schema.org/CreativeWork">Crossley, Scott A., Kristopher Kyle, and Danielle S. McNamara. 2016. “The tool for the automatic analysis of text cohesion (TAACO): Automatic assessment of local, global, and text cohesion.” <span style="font-style:italic" itemprop="hi">Behavior research methods</span> 48, No. 4: 1227-37.</li><li id="Dale.1948" itemscope="" itemtype="https://schema.org/CreativeWork">Dale, Edgar, and Jeanne S. Chall. 1948. “A formula for predicting readability: Instructions.” <span style="font-style:italic" itemprop="hi">Educational research bulletin</span>: 37-54.</li><li id="Dębowski.2015" itemscope="" itemtype="https://schema.org/CreativeWork">Dębowski, Łukasz, Bartosz Broda, Bartłomiej Nitoń, and Edyta Charzyńska. 2015. “Jasnopis–A Program to Compute Readability of Texts in Polish Based on Psycholinguistic Research.” In <span style="font-style:italic" itemprop="hi">Natural Language Processing and Cognitive Science</span>, edited by B. Sharp, W Lubaszewski and R. Delmonte, 51-61. Liberia Editrice Cafoscarina.</li><li id="Fišer.2014" itemscope="" itemtype="https://schema.org/CreativeWork">Fišer, Darja, Tomaž Erjavec, Ana Zwitter Vitez, and Nikola Ljubešić. 2014. “JANES se predstavi: metode, orodja in viri za nestandardno pisno spletno slovenščino.” In <span style="font-style:italic" itemprop="hi">Language technologies : proceedings of the 17th International Multiconference Information Society - IS 2014</span>, edited by Tomaž Erjavec and Jerneja Žganec Gros, 56-61. Ljubljana: Jožef Stefan Institute.</li><li id="François.2012" itemscope="" itemtype="https://schema.org/CreativeWork">François, Thomas, and Eleni Miltsakaki. 2012. “Do NLP and machine learning improve traditional readability formulas?” In <span style="font-style:italic" itemprop="hi">Proceedings of the First Workshop on Predicting and Improving Text Readability for target reader populations</span>, edited by Sandra Williams, Advaith Siddharthan and Ani Nenkova, 49-57. Association for Computational Linguistics.</li><li id="Grčar.2012" itemscope="" itemtype="https://schema.org/CreativeWork">Grčar, Miha, Simon Krek, and Kaja Dobrovoljc. 2012. “Obeliks: statisticni oblikoskladenjski oznacevalnik in lematizator za slovenski jezik.” In <span style="font-style:italic" itemprop="hi">Proceedings of the Eighth Language Technologies Conference, </span>edited by Tomaž Erjavec and Jerneja Žganec Gros, 89-94. Ljubljana: Jožef Stefan Institute.</li><li id="Gunning.1952" itemscope="" itemtype="https://schema.org/CreativeWork">Gunning, Robert. 1952. <span style="font-style:italic" itemprop="hi">The technique of clear writing</span>. McGraw-Hill.</li><li id="Justin.2003" itemscope="" itemtype="https://schema.org/CreativeWork">Justin, J. 2003. <span style="font-style:italic" itemprop="hi">Učbenik kot dejavnik uspešnosti kurikularne prenove: poročilo o rezultatih evalvacijske študije.</span></li><li id="Kilgarriff.2014" itemscope="" itemtype="https://schema.org/CreativeWork">Kilgarriff, Adam, Frieda Charalabopoulou, Maria Gavrilidou, Janne Bondi Johannessen, Saussan Khalil, Sofie Johansson Kokkinakis, Robert Lew, Serge Sharoff, Ravikiran Vadlapudi, and Elena Volodina. 2014. “Corpus-based vocabulary lists for language learners for nine languages.” <span style="font-style:italic" itemprop="hi">Language resources and evaluation</span> 48, No. 1: 121-63.</li><li id="Kincaid.1975" itemscope="" itemtype="https://schema.org/CreativeWork">Kincaid, J. Peter, Robert P. Fishburne Jr, Richard L. Rogers, and Brad S. Chissom. 1975. <span style="font-style:italic" itemprop="hi">Derivation of new readability formulas (Automated Readability Index, Fog Count and Flesch Reading Ease formula) for navy enlisted personnel</span>. Report No. 8-75.</li><li id="Kononenko.2007" itemscope="" itemtype="https://schema.org/CreativeWork">Kononenko, Igor, and Matjaž Kukar. 2007. <span style="font-style:italic" itemprop="hi">Machine learning and data mining</span>. Chichester, Horwood Publishing.</li><li id="Kosem.2011" itemscope="" itemtype="https://schema.org/CreativeWork">Kosem, Iztok, Tadeja Rozman, and Mojca Stritar. 2011. “How do Slovenian primary and secondary school students write and what their teachers correct: A corpus of student writing.” In <span style="font-style:italic" itemprop="hi">Proceedings of Corpus Linguistics Conference 2011, ICC Birmingham</span>, 20-22.</li><li id="LogarBerginc.2009" itemscope="" itemtype="https://schema.org/CreativeWork">Logar Berginc, Nataša, and Simon Šuster. 2009. “Gradnja novega korpusa slovenščine.” <span style="font-style:italic" itemprop="hi">Jezik in slovstvo</span> 54: 57-68.</li><li id="LogarBerginc.2012" itemscope="" itemtype="https://schema.org/CreativeWork">Logar Berginc, Nataša, Miha Grčar, Marko Brakus, Tomaž Erjavec, Špela Arhar Holdt, Simon Krek, and Iztok Kosem. 2012. <span style="font-style:italic" itemprop="hi">Korpusi slovenskega jezika Gigafida, KRES, ccGigafida in ccKRES: gradnja, vsebina, uporaba</span>. Ljubljana: Trojina, zavod za uporabno slovenistiko and Faculty of Social Sciences.</li><li id="Lu.2009" itemscope="" itemtype="https://schema.org/CreativeWork">Lu, Xiaofei. 2009. “Automatic measurement of syntactic complexity in child language acquisition.” <span style="font-style:italic" itemprop="hi">International Journal of Corpus Linguistics</span> 14, No. 1: 3-28.</li><li id="McLaughlin.1969" itemscope="" itemtype="https://schema.org/CreativeWork">Mc Laughlin, G. Harry. 1969. “SMOG grading - a new readability formula.” <span style="font-style:italic" itemprop="hi">Journal of reading</span> 12, No. 8: 639-46.</li><li id="Senter.1967" itemscope="" itemtype="https://schema.org/CreativeWork">Senter, R. J., and Edgar A. Smith. 1967. <span style="font-style:italic" itemprop="hi">Automated readability index</span>. Ohio; University of Cincinnati.</li><li id="Sherman.1893" itemscope="" itemtype="https://schema.org/CreativeWork">Sherman, Lucius Adelno. 1893. <span style="font-style:italic" itemprop="hi">Analytics of literature: A manual for the objective study of English prose and poetry</span>. Boston: Ginn.</li><li id="Škvorc.2018" itemscope="" itemtype="https://schema.org/CreativeWork">Škvorc, Tadej, Simon Krek, Senja Pollak, Špela Arhar Holdt, and Marko Robnik-Šikonja. 2018. “Evaluation of Statistical Readability Measures on Slovene texts.” In <span style="font-style:italic" itemprop="hi">Proceedings of the conference on Language Technologies &amp; Digital Humanities 2018,</span> edited by Darja Fišer and Andrej Pančur, 240-47<span style="font-style:italic" itemprop="hi">.</span> Ljubljana: Ljubljana University Press, Faculty of Arts.</li><li id="Spache.1953" itemscope="" itemtype="https://schema.org/CreativeWork">Spache, George. 1953. “A new readability formula for primary-grade reading materials.” <span style="font-style:italic" itemprop="hi">The Elementary School Journal</span> 53, No. 7: 410-13.</li><li id="Verdonik.2011" itemscope="" itemtype="https://schema.org/CreativeWork">Verdonik, Darinka, Ana Zwitter Vitez, and Hotimir Tivadar. 2011. <span style="font-style:italic" itemprop="hi">Slovenski govorni korpus Gos</span>. Trojina, zavod za uporabno slovenistiko.</li><li id="Wiersma.2010" itemscope="" itemtype="https://schema.org/CreativeWork">Wiersma, Wybo, John Nerbonne, and Timo Lauttamus. 2010. “Automatically extracting typical syntactic differences from corpora.” <span style="font-style:italic" itemprop="hi">Literary and Linguistic Computing</span> 26, No. 1: 107-24.</li><li id="ZwitterVitez.2014" itemscope="" itemtype="https://schema.org/CreativeWork">Zwitter Vitez, Ana. 2014. “Ugotavljanje avtorstva besedil: primer »Trenirkarjev«.” In <span style="font-style:italic" itemprop="hi">zbornik Devete konference Jezikovne Tehnologije Informacijska družba – IS</span>, edited by Tomaž Erjavec and Jerneja Žganec Gros, 131-34. Ljubljana: Jožef Stefan Institute.</li></ul></section><section class="summary" id="index-back.1_div.2"><p class="docAuthor">Tadej Škvorc, Simon Krek, Senja Pollak, Špela Arhar Holdt, Marko Robnik-Šikonja</p><header><h2><span style="text-transform: uppercase;" itemprop="head">Predicting Slovene text complexity using readability measures</span><br class="subheader" itemprop="head" /><span class="subheader" itemprop="head">SUMMARY</span></h2></header><p id="index-p-d46e1745"><span class="numberParagraph">1</span>In English, the problem of determining text readability (i.e. how easy a text is to understand) has long been a topic of research, with its origins in the 19th century. Since then, many different methods and readability measures have been developed, often with the goal of determining whether a text is too difficult for its target age group. Even though the question of readability is complex from a linguistic standpoint, a large majority of existing measures are based on simple heuristics. Since most of these measures were developed for English texts, it is hard to say how well they would perform on Slovene texts. Measures designed for English are designed to correspond with the American school system, are sometimes based on pre-constructed lists of easy words which do not exist for Slovene and do not take into account morphological information when determining whether a word is difficult or not. </p><p id="index-p-d46e1746"><span class="numberParagraph">2</span>In our work, we analyze some common readability measures on Slovene text. We also introduce and analyze two additional readability criteria that do not appear in any of the analyzed readability measures: <span style="font-weight:bold" itemprop="hi">morphological difficulty</span>, where we assume word forms that appear rarely are harder to understand than the ones that appear commonly and the <span style="font-weight:bold" itemprop="hi">context of difficult words, </span>where we assume difficult words are easier to understand in a context of simple words, as their meaning can be inferred from that context. We performed the analysis on 14,581 text documents from the Gigafida corpus, which were split into five groups based on their target audience (childrens’ magazines, pop magazines, newspaper articles, computer magazines, and transcriptions of sessions of the National Assembly). We assumed that the groups should have different readability scores due to their differing target audiences and writing styles.</p><p id="index-p-d46e1754"><span class="numberParagraph">3</span>For each analyzed readability measure we checked how well it separates texts from different groups. We did this by first obtaining the statistical distribution of readability scores for texts in each group and checking how much the distributions differ. We show that a number of common readability measures designed for English work well on Slovene texts. To determine which of the measures perform the best we used several statistical tests.</p><p id="index-p-d46e1755"><span class="numberParagraph">4</span>We also show that machine-learning methods can be used to accurately (over 98% chance of a correct prediction) predict which group a text belongs to based on its readability scores. We trained four different machine-learning models (decision trees, random forests, naïve Bayes classifier, and extreme gradient boosting) and evaluated them on our dataset. We obtained the best result (98.4% classification accuracy) by using random forests.</p></section><section class="summary" id="index-back.1_div.3"><p class="docAuthor">Tadej Škvorc, Simon Krek, Senja Pollak, Špela Arhar Holdt, Marko Robnik-Šikonja</p><header><h2><span style="text-transform: uppercase;" itemprop="head">Napovedovanje kompleksnosti slovenskih besedil z uporabo mer berljivosti</span><br class="subheader" itemprop="head" /><span class="subheader" itemprop="head">POVZETEK</span></h2></header><p id="index-p-d46e1762"><span class="numberParagraph">1</span>Problem berljivosti (t.j. kako enostavno je besedilo za branje) je v angleščini dobro raziskan. Obstaja veliko različnih metod in formul, s katerimi lahko analiziramo angleška besedila z vidika berljivosti. Kljub temu, da je vprašanje berljivosti z lingvističnega vidika zapleteno večina metod za ugotavljanje berljivosti temelji na preprostih značilnostih besedil. Ker je bila večina mer berljivosti zasnovanih za angleška besedila, ne moremo biti prepričani da bodo enako dobro delovala na slovenskih besedilih. Angleške mere berljivosti so namreč usklajene z ameriškim šolskim sistemom, včasih temeljijo na vnaprej sestavljenih seznamih lahkih besed in ne upoštevajo težavnosti besed z morfološkega vidika.</p><p id="index-p-d46e1763"><span class="numberParagraph">2</span>V našem delu analiziramo pogoste mere berljivosti na slovenskih besedilih. Poleg tega uvedemo in analiziramo dva dodatna kazalnika berljivosti ki ne nastopata v pogostih merah berljivosti: <span style="font-weight:bold" itemprop="hi">morfološka zahtevnost besed</span>, s katero želimo zajeti predpostavko da so redkejše morfološke oblike besed težko berljive, in <span style="font-weight:bold" itemprop="hi">kontekst težkih besed</span>, s katero želimo zajeti predpostavko, da so neznane besede, ki se pojavijo v kontekstu znanih besed lažje berljive, saj lahko njihov pomen razberemo iz konteksta. Analizo smo izvedli na 14,581 besedilih iz korpusa Gigafida, ki smo jih razdelili v pet skupin glede na njihovo ciljno publiko (Otroške revije, splošne revije, časopisni članki, računalniške revije in transkripcije sej Državnega zbora). Predpostavili smo, da imajo revije zaradi različnih ciljnih publik in tematik različne sloge pisanja in posledično različne stopnje berljivosti.</p><p id="index-p-d46e1771"><span class="numberParagraph">3</span>Za vsako izmed mer berljivosti smo preverili, kako dobro med seboj loči besedila iz različnih skupin. Za vsako izmed njih smo pridobili statistično distribucijo vrednosti berljivosti vsake skupine in preverili, ali so distribucije ustrezno ločene. V analizi pokažemo, da se številne uveljavljene mere, ki so bile zasnovane za angleščino, dobro obnesejo tudi na slovenskih besedilih. Da bi ugotovili, katere mere najbolje razlikujejo med skupinami smo uporabili statistične teste. </p><p id="index-p-d46e1772"><span class="numberParagraph">4</span>Poleg tega pokažemo, da lahko z modeli strojnega učenja in kombinacijo analiziranih metod berljivosti z visoko točnostjo (nad 98%) napovemo, v katero skupino spada določeno besedilo. Za to analizo smo uporabili štiri različne metode strojnega učenja (odločitvena drevesa, naključne gozdove, naivni Bayesov klasifikator, in extreme gradient boosting). Najboljši rezultat (98,4%) smo dobili z metodo naključnih gozdov.</p></section></div><!--Notes in [TEI]--><div class="notes"><div class="noteHeading">Notes</div><div class="note" id="ftn1"><p><a class="link_return" title="Pojdi nazaj k besedilu" href="#ftn1_return"><sup>*</sup></a> <span class="noteBody">University of Ljubljana, Faculty of Computer and Information Science, Večna Pot 113, SI-1000 Ljubljana, Jožef Stefan Institute, Jamova cesta 39, SI-1000 Ljubljana, <a class="link_ref" itemprop="ref" href="mailto:tadej.skvorc@fri.uni-lj.si">tadej.skvorc@fri.uni-lj.si</a></span></p></div><div class="note" id="ftn2"><p><a class="link_return" title="Pojdi nazaj k besedilu" href="#ftn2_return"><sup>**</sup></a> <span class="noteBody">Jožef Stefan Institute, Jamova cesta 39, SI-1000 Ljubljana, University of Ljubljana, Faculty of Arts, Aškerčeva 2, SI-1000 Ljubljana, <a class="link_ref" itemprop="ref" href="mailto:simon.krek@guest.arnes.si">simon.krek@guest.arnes.si</a></span></p></div><div class="note" id="ftn3"><p><a class="link_return" title="Pojdi nazaj k besedilu" href="#ftn3_return"><sup>∗∗∗</sup></a> <span class="noteBody">Jožef Stefan Institute, Jamova cesta 39, SI-1000 Ljubljana, <a class="link_ref" itemprop="ref" href="mailto:senja.pollak@ijs.si">senja.pollak@ijs.si</a></span></p></div><div class="note" id="ftn4"><p><a class="link_return" title="Pojdi nazaj k besedilu" href="#ftn4_return"><sup>∗∗∗∗</sup></a> <span class="noteBody">University of Ljubljana, Faculty of Arts, Aškerčeva 2, SI-1000 Ljubljana, University of Ljubljana, Faculty of Computer and Information Science, Večna Pot 113, SI-1000 Ljubljana, <a class="link_ref" itemprop="ref" href="mailto:spela.arharholdt@ff.uni-lj.si">spela.arharholdt@ff.uni-lj.si</a></span></p></div><div class="note" id="ftn5"><p><a class="link_return" title="Pojdi nazaj k besedilu" href="#ftn5_return"><sup>∗∗∗∗∗</sup></a> <span class="noteBody">University of Ljubljana, Faculty of Computer and Information Science, Večna Pot 113, SI-1000 Ljubljana, <a class="link_ref" itemprop="ref" href="mailto:marko.robnik@fri.uni-lj.si">marko.robnik@fri.uni-lj.si</a></span></p></div></div><script src="http://www2.sistory.si/publikacije/themes/foundation/6/js/vendor/what-input.js"></script><script src="http://www2.sistory.si/publikacije/themes/foundation/6/js/vendor/foundation.min.js"></script><script src="http://www2.sistory.si/publikacije/themes/foundation/6/js/app.js"></script><script src="http://www2.sistory.si/publikacije/themes/js/plugin/back-to-top/back-to-top.js"></script></div></body></html>